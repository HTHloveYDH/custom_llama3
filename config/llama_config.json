{
    "model_type": "llama3_1B", 
    "pos_encode": "rope", 
    "tokenizer_path": "./tokenizer/llama3/tokenizer.model", 

    "load_weights": null,
    "ckpt_path": "", 

    "lora": false, 
    "lora_alpha": 1,
    "lora_rank": 1, 

    "dist": {
        "dp": 1, 
        "tp": 1, 
        "pp": 1, 

        "dp_shard" : false, 
        "compiled_autograd": false, 
        "mixed_precision_reduce": "float32", 
        "mixed_precision_param": "float32", 

        "parallel_loss": false, 
        "async_tp": false, 
        "float8": false, 

        "pipeline_parallel_schedule": "gpipe", 
        "pipeline_parallel_microbatches": 2, 

        "activation_checkpoint_mode": null,
        "selective_ac_option": "op", 
        "compile": false
    },

    "params": {
        "dim": 256, 
        "n_layers": 6, 
        "n_heads": 4, 
        "n_kv_heads": 2, 
        "vocab_size": 128256, 
        "multiple_of": 1024, 
        "ffn_dim_multiplier": 1.3, 
        "norm_eps": 1e-5, 
        "rope_theta": 500000.0, 
        "max_batch_size": 4, 
        "max_seq_len": 1024, 
        "long_term_memory": false, 
        "norm_type": "rmsnorm"
    }
}
